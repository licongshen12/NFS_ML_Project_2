{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc4cb684-9949-48e0-bcc4-a606a766cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Import Natural Language Toolkit\n",
    "import nltk\n",
    "\n",
    "#Import Beautiful Soup\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "#Import string for list of punctuation\n",
    "import string\n",
    "\n",
    "#Import stop word list\n",
    "from nltk.corpus import stopwords as stopwords\n",
    "\n",
    "#Import tokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "#Import Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Import Stemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2c9a587-6c63-44fd-82a2-621edc138294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/ASUS/Desktop/NFSML/Project 2 (NLP Binary Classification)/stock_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b44aa26c-2caa-4f16-bde5-23753e379aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2facd728-c370-452c-bd74-cb9f2b5f1a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Kickers on my watchlist XIDE TIT SOQ PNK CPW B...\n",
       "1    user AAP MOVIE 55 return for the FEAGEED indic...\n",
       "2    user Id be afraid to short AMZN  they are look...\n",
       "3                                     MNTA Over 1200  \n",
       "4                                      OI  Over 2137  \n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_punctuation(x))\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e691bba9-a994-4590-ac70-92463d75c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f032d3e1-6522-47e0-9c07-e604dba0f5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [kickers, on, my, watchlist, xide, tit, soq, p...\n",
       "1     [user, aap, movie, 55, return, for, the, feage...\n",
       "2     [user, id, be, afraid, to, short, amzn, they, ...\n",
       "3                                    [mnta, over, 1200]\n",
       "4                                      [oi, over, 2137]\n",
       "5                                     [pgnx, over, 304]\n",
       "6     [aap, user, if, so, then, the, current, downtr...\n",
       "7     [mondays, relative, weakness, nyx, win, tie, t...\n",
       "8     [goog, ower, trend, line, channel, test, volum...\n",
       "9         [aap, will, watch, tomorrow, for, ong, entry]\n",
       "10    [im, assuming, fcx, opens, tomorrow, above, th...\n",
       "11    [it, really, worries, me, how, everyone, expec...\n",
       "12    [aap, gamcos, arry, haverty, apple, is, extrem...\n",
       "13    [user, maykiljil, posted, that, i, agree, that...\n",
       "14    [momentum, is, coming, back, to, etfc, broke, ...\n",
       "15    [ha, hitting, 3565, means, resume, targeting, ...\n",
       "16    [user, gameplan, shot, for, today, but, i, lik...\n",
       "17    [with, fcx, gapping, well, above, ideal, entry...\n",
       "18    [user, great, list, again, particularly, like,...\n",
       "19                           [athx, upper, trend, line]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize\n",
    "df['Text'] = df['Text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['Text'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47c02b2c-4c22-4e97-a9a7-38e6668a8bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [kickers, watchlist, xide, tit, soq, pnk, cpw,...\n",
       "1    [user, aap, movie, 55, return, feageed, indica...\n",
       "2    [user, id, afraid, short, amzn, looking, like,...\n",
       "3                                         [mnta, 1200]\n",
       "4                                           [oi, 2137]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stop words\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_stopwords(x))\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d5237c8-4119-4209-b83c-a38a8d136e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    kicker watchlist xide tit soq pnk cpw bpz aj t...\n",
       "1    user aap movie 55 return feageed indicator 15 ...\n",
       "2    user id afraid short amzn looking like nearmon...\n",
       "3                                            mnta 1200\n",
       "4                                              oi 2137\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Lemmatize\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = \" \".join([lemmatizer.lemmatize(i) for i in text])\n",
    "    return lem_text\n",
    "\n",
    "df['Text'] = df['Text'].apply(lambda x: word_lemmatizer(x))\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d30c42b-a989-46e8-9948-d34cc971084c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    kicker watchlist xide tit soq pnk cpw bpz aj t...\n",
       "1    user aap movi 55 return feage indic 15 trade y...\n",
       "2    user id afraid short amzn look like nearmonopo...\n",
       "3                                            mnta 1200\n",
       "4                                              oi 2137\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Stemming\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text\n",
    "\n",
    "df['Text'] = df['Text'].apply(lambda x: word_stemmer(x))\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc959092-f454-48d4-b7ab-c9416a2afe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'],\n",
    "                                                    df['Sentiment'],\n",
    "                                                    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12ea69de-53ee-4996-8a0e-973ef812ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "#Preparing the cvec & tfidf X data\n",
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b949f2f-9d52-46cf-8331-48280071597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b76ba7ce-95a5-446b-8934-a4ef473745d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes(tfidf) Accuracy Score ->  72.78481012658227\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes and tfidf\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train_tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test_tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes(tfidf) Accuracy Score -> \",accuracy_score(predictions_NB, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a195875-c6ad-49ff-b60c-670059bde126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes(cvec) Accuracy Score ->  76.23705408515535\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes and cvec\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train_cvec,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test_cvec)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes(cvec) Accuracy Score -> \",accuracy_score(predictions_NB, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "262919cd-6287-4df2-8938-af70e28449d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(tfidf) Accuracy Score ->  78.25086306098964\n"
     ]
    }
   ],
   "source": [
    "# SVM and tfidf\n",
    "\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_tfidf,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM(tfidf) Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f8ddd70-df49-4d6e-899b-024c414b5b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(cvec) Accuracy Score ->  76.2945914844649\n"
     ]
    }
   ],
   "source": [
    "# SVM and cvec\n",
    "\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_cvec,y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test_cvec)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM(cvec) Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88513f57-108b-4dbf-b07b-56a625016e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on tfidf vectorized data (without stemming) performed the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
